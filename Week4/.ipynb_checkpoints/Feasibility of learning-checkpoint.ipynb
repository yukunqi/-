{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习的可行性\n",
    "\n",
    "这一次课程讨论的问题是，机器学习真的可行吗？我们真的可以通过机器学习来找个一个比较完美的函数，这个函数能够得到一个好的结果。\n",
    "\n",
    "那么整个课程最核心的问题就是，我们是否可以通过机器学习算法(learning_algorithm)来从hypothesis_set里面找到一个函数h，这个函数和我们想要的f完美函数很接近，在整个数据X范围内。如果这样可以，那么我们的机器学习才是有意义的。\n",
    "\n",
    "\n",
    "我们可以把这上面的事情比做一个比较具体化的东西，\n",
    "\n",
    "1.一罐子弹珠\n",
    "2.把弹珠涂成橙色还是绿色\n",
    "\n",
    "那么我们的整个罐子的弹珠其实就是数据范围X，然后把猜测弹珠颜色的过程就是h(x),如果结果是正就绿色，如果是负就橙色。\n",
    "\n",
    "那么我们不知道这个很大很大的罐子里面到底出现橙色的概率是多少，你数不清楚。这是我们想知道的，\n",
    "\n",
    "那么我们可以通过抽样的方式来估计看看，怎么做呢？我们可以假设抽取100个弹珠，然后猜测它的颜色是什么样的？\n",
    "\n",
    "在有监督的学习的情况下，我们还知道这些样本里面到底y是多少，是正还是负(也就是弹珠真正的颜色是绿色还是橙色)\n",
    "\n",
    "这个y其实就类似于f(x)的结果了。可惜我们不知道我们的f\n",
    "\n",
    "<img src='./pic1.png' width='60%' height='60%'>\n",
    "\n",
    "\n",
    "那么我们可以通过样本的错误率去估算说整体空间的错误率，这样你可以知道你的这个h和我们完美的f不一样的概率是多少。\n",
    "\n",
    "Ein代表的意思就是在样本里面我们计算的h和f不一样的概率是多少\n",
    "Eout代表的意思就是在整个X范围内h和f不一样的概率是多少\n",
    "\n",
    "那么为什么这个Ein和Eout会比较接近呢？因为如果接近我们才能用样本的Ein来说我们这个Eout的好和坏，进而得出结论我们这个h和f是不是很像\n",
    "\n",
    "\n",
    "Hoeffding's inequality这个公式提供了理由\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{P}=\\left [| E_{in}\\left ( h \\right )-E_{out}(h) \\right |>\\varepsilon ]\\leq 2exp(-2\\varepsilon ^{2}N)\n",
    "\\end{align}$$\n",
    "\n",
    "这个公式的意思是Ein和Eout差距大于$\\varepsilon$的概率会很小，小于后面的那个值。\n",
    "\n",
    "所以我们可以这么做，没问题。\n",
    "\n",
    "总结一下：说的就是我们的整个X空间范围内，假设服从一个未知的分布P。然后从里面抽取了一个大小为N的样本出来，然后再假设我们存在一个hypothesis set 里面有很多的h，然后对于每一个修正过的h来说，它会去计算样本集里面的样本，得到一个错误率，这个是Ein，然后我们通过这个错误率来推算出Eout，什么是Eout？就是还是同样的这个h去计算X空间内剩余部分的数据时得到的错误率。那推算出来的理由是什么？凭什么可以这样做，因为有Hoeffding's inequality，这个不等式说的是，在一个比较大的样本范围内，对于任意的h，样本的错误率和真实的错误率的差值大于ε的概率非常小(具体详情参考这个不等式的定义)。所以就成立了，所以我们可以利用样本的错误率来推出真实的错误率。英文叫PAC，那上面推出了样本和真实的错误率相等，如果再加上样本的错误率很小的话，代表真实的错误率就很小。那么我们这个h就非常符合完美的target函数。所以可以利用这个方法去判断说这个h到底好还是不好。\n",
    "\n",
    "到这里为止我们可以通过Ein和Eout来判断说这个h到底是好函数还是坏函数\n",
    "\n",
    "#### 那我们要选择一个Ein很小的，这样就可以得到很接近f的h了，可是直接选Ein很小就可以吗？万一Ein很小，但是实际Eout很大怎么办？\n",
    "\n",
    "\n",
    "这里说的情况是可能发生的，例子举的是假设有一个铜板，让你抛五次，然后你五次都抛出了正面，那么这个铜板难道就和别的铜板不一样吗？难道它抛出正面的概率不应该是0.5吗？但是这个时候如果你使用了这个铜板的h，它会告诉你说Ein为0，那么你Eout通过前面的公式和内容来判断说应该也为近似0的值，你觉得不错，就采用了这个h。但是实际上我们知道铜板的Eout为0.5所以这里就会发生不好的数据，我们称为Bad，而且这种事情发生的概率会随着执行的次数增多而恶化，比如让你进行100次试验，你会发现至少其中一次发生5次正面的概率很大，那么你惨了，你肯定选这个h来作为你的结果。那么后果可能会很严重，所以对于一个h来说，肯定会有存在这样的Bad的数据出现，这个是很正常的事情。\n",
    "\n",
    "那么我们如果有很多很多次抽样，形成很多很多的数据D1，D2，D3....一直到Dn，那么hoeffding能够保证的事情是什么？能够保证的是，在这么多D里面，发生BAD的情况会很小，小于hoeffding右边的那个值。\n",
    "\n",
    "如果有很多很多的hypothesis，那么通过图就可以看到每一行对应当前hypothesis的BAD数据发生的概率。这么多的D和这么多的h发生的BAD的概率又是多少呢？\n",
    "\n",
    "<img src='./pic2.png' width='60%' height='60%'>\n",
    "\n",
    "通过推到出来知道说，大概整个发生BAD的概率是这样的，那么最合理的learning_algorithm就是LPA或者Pocket算法了。\n",
    "\n",
    "<img src='./pic3.png' width='60%' height='60%'>\n",
    "\n",
    "最后的结论就是：在有限的h里面，有很大的D的范围下。我们算法自由的做选择，无论哪个h被选择，它们的Ein和Eout都会近似接近。然后选择一个Ein很小的(比如等于0)h作为我们的g，这代表Eout也很小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
